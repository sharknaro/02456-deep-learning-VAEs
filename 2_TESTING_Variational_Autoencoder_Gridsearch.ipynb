{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1413e46c-6a93-46c3-ac3e-7314c516a08a",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "This was done using Ray Tune with the ASHA Scheduler using a simple grid search approach. <br>\n",
    "We used a random 20% subset of our full data for the hyperparameter optimiaztion due to time constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1597afd6-68ce-4391-8350-2c984887551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, clear_output\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "import time\n",
    "import sklearn\n",
    "import ray\n",
    "\n",
    "from typing import *\n",
    "from collections import defaultdict\n",
    "from warnings import simplefilter\n",
    "\n",
    "from ray import tune, air\n",
    "from ray.air import session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torch.distributions.binomial import Binomial\n",
    "from torch.distributions.log_normal import LogNormal\n",
    "from torch.utils.data import random_split, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00acee8b-a8dd-4e1c-b193-d3ff4fee4123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 15:39:59,774\tINFO worker.py:1519 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '172.27.30.56', 'raylet_ip_address': '172.27.30.56', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-12-21_15-39-58_043542_6642/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-12-21_15-39-58_043542_6642/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-12-21_15-39-58_043542_6642', 'metrics_export_port': 63571, 'gcs_address': '172.27.30.56:61180', 'address': '172.27.30.56:61180', 'dashboard_agent_listen_port': 52365, 'node_id': 'faf75b55bdd4dc7130147b63f0e19facb5db516047371e7bf5d84fa8'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initalize ray tune to run on GPU\n",
    "ray.init(num_gpus = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679e3d3-9f54-4975-8bc1-92c231f853c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function for plotting during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d8d146-10b0-4dbb-9ad7-fedfd1333ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(training_data, validation_data, x, x_hat, tmp_img=\"tmp_vae_out.png\"):\n",
    "    \n",
    "    fig, axes = plt.subplot_mosaic([['top_left', 'top_centre', 'top_right'],\n",
    "                                    ['mid', 'mid', 'mid'],\n",
    "                                    ['bottom', 'bottom', 'bottom']])\n",
    "    \n",
    "    fig.set_size_inches(15, 10)\n",
    "    \n",
    "    # plot ELBO\n",
    "    axes['top_left'].set_title(r'ELBO: $\\mathcal{L} ( \\mathbf{x} )$')\n",
    "    axes['top_left'].plot(training_data['elbo'], label='Training')\n",
    "    axes['top_left'].plot(validation_data['elbo'], label='Validation')\n",
    "    axes['top_left'].legend()\n",
    "    \n",
    "    # plot KL\n",
    "    axes['top_centre'].set_title(r'$\\mathcal{D}_{\\operatorname{KL}}\\left(q_\\phi(\\mathbf{z}|\\mathbf{x})\\ |\\ p(\\mathbf{z})\\right)$')\n",
    "    axes['top_centre'].plot(training_data['kl'], label='Training')\n",
    "    axes['top_centre'].plot(validation_data['kl'], label='Validation')\n",
    "    axes['top_centre'].legend()\n",
    "    \n",
    "    \n",
    "    # plot NLL\n",
    "    axes['top_right'].set_title(r'$\\log p_\\theta(\\mathbf{x} | \\mathbf{z})$')\n",
    "    axes['top_right'].plot(training_data['log_px'], label='Training')\n",
    "    axes['top_right'].plot(validation_data['log_px'], label='Validation')\n",
    "    axes['top_right'].legend()\n",
    "    \n",
    "    # plot sample\n",
    "    axes['mid'].set_title(r'Observation $\\mathbf{x}$')\n",
    "    axes['mid'].imshow(x, cmap=\"plasma\", aspect=\"auto\")\n",
    "    a = axes['mid'].imshow(x, cmap=\"plasma\", aspect=\"auto\")\n",
    "    plt.colorbar(a, ax = axes['mid'], location='right')\n",
    "    \n",
    "    # plot reconstruction\n",
    "    axes['bottom'].set_title(r'Reconstruction $\\mathbf{\\hat x \\sim p(x|z)}$')\n",
    "    axes['bottom'].imshow(x_hat, cmap=\"plasma\", aspect=\"auto\")\n",
    "    b = axes['bottom'].imshow(x_hat, cmap=\"plasma\", aspect=\"auto\")\n",
    "    plt.colorbar(b, ax = axes['bottom'], location='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(tmp_img)\n",
    "    plt.close(fig)\n",
    "    display(Image(filename=tmp_img))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    os.remove(tmp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bd508c-dd50-46be-b7dc-3398d44df886",
   "metadata": {},
   "source": [
    "# Dataloader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c654b762-e32a-4d18-aee6-59ce3d2e29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loaders(DATA_PATH=os.getcwd() + \"/Data/archs4_data_transformed.npy\", batch_size=32, num_workers=4, pin_memory=True):\n",
    "    # print(\"LOADING DATA ...\")\n",
    "    start = time.time()\n",
    "    data = np.load(DATA_PATH)\n",
    "    end = time.time()\n",
    "\n",
    "    assert np.isnan(np.sum(data)) == False\n",
    "    \n",
    "    inputs = torch.from_numpy(data)\n",
    "    inputs_train, inputs_test = random_split(inputs, [0.8,0.2])\n",
    "    \n",
    "    # Training data:\n",
    "    train_loader = DataLoader(dataset = inputs_train,\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory)\n",
    "\n",
    "    # Testing data:\n",
    "    test_loader = DataLoader(dataset = inputs_test,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = True,\n",
    "                         num_workers=num_workers, \n",
    "                         pin_memory=pin_memory)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd7d94-1be2-4196-9f74-afb9ff155842",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining custom distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524bfe06-bc3c-4ca2-916f-c869295b47fc",
   "metadata": {},
   "source": [
    "#### After log2(x+1) and quantile transformation, our data follows a hurdle normal distribution which is implemented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ce8e09-f3ba-47d1-8d37-57f301ce73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HurdleNormal(Distribution):\n",
    "    \"\"\"\n",
    "    A hurdle model of the Bernoulli and normal distributions to model data which is normally distributed with an excess probability mass at 0\n",
    "    Hurdle Normal PDF:\n",
    "    p(x | mu, sigma, p) = p for x=0\n",
    "    p(x | mu, sigma, p) = (1-p) * normal distribution pdf\n",
    "    This is to be used as observation model p(x|z): p(x | z, mu, sigma, p)\n",
    "    \"\"\"\n",
    "    def __init__(self, mu:Tensor, log_sigma:Tensor, p_logits:Tensor):\n",
    "        assert mu.shape == log_sigma.shape == p_logits.shape, f\"Tensors 'mu': {mu.shape}, 'log_sigma': {log_sigma.shape} and 'p': {p_logits.shape} must be of the same shape.\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp() + 0.01 # to avoid sigma being zero\n",
    "        self.p_logits = p_logits\n",
    "\n",
    "        self.Bernoulli = torch.distributions.bernoulli.Bernoulli(logits = self.p_logits)\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `x ~ hurdle_normal(x | mu, sigma, p)`\"\"\"\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Bernoulli returns either 0 or 1, and for 1 we want the value from the sampled log_normal distribution so we just multiply them\n",
    "            B = self.Bernoulli.sample() \n",
    "            norm = torch.distributions.normal.Normal(self.mu, self.sigma).sample()\n",
    "            return B*norm\n",
    "            \n",
    "    def log_prob(self, x:Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        return log probability: log p(x)\n",
    "        for x=0:\n",
    "            p(x|mu, sigma, p) = p \n",
    "        for x > 0\n",
    "            p(x|mu, sigma, p) = (1-p) * 1 / (sigma * sqrt(2*pi)) * exp(-0.5 * ((x - mu) / sigma)) \n",
    "        \"\"\"\n",
    "        \n",
    "        idx = x > 0.\n",
    "        \n",
    "        # Log prob of zero values = log p\n",
    "        # Using torch.zeros as for the places where x is not 0 we want (1-p)\n",
    "        bernoulli_tensor = torch.zeros_like(x)\n",
    "        bernoulli_tensor[idx] = 1.\n",
    "        \n",
    "        log_prob_bernoulli = self.Bernoulli.log_prob(bernoulli_tensor)\n",
    "        \n",
    "        log_prob_normal = torch.distributions.normal.Normal(loc = self.mu[idx], scale = self.sigma[idx]).log_prob(x[idx])\n",
    "        log_prob_normal = torch.zeros_like(log_prob_bernoulli).masked_scatter(idx, log_prob_normal)\n",
    "        \n",
    "        # FINAL LOG PROB\n",
    "        log_p = log_prob_bernoulli + log_prob_normal # Log prob will be log(p) when x=0 and log(p-1) + logprob_normal when x>0\n",
    "\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32b975-fcee-4eae-8e27-ba2e81476dd3",
   "metadata": {},
   "source": [
    "#### The reparameterization trick to be able to backpropagate despite random sampling is used as implemented in the course exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f32fd5d-d78d-4c06-8519-a6d56b757410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp() + 0.001\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        return self.mu + self.sigma * self.sample_epsilon() \n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        return torch.distributions.normal.Normal(self.mu, self.sigma).log_prob(z)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ReparameterizedDiagonalGaussian(mu={self.mu.shape}, sigma={self.sigma.shape})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccff15e-93e5-45bc-bf65-5dd967a2efce",
   "metadata": {},
   "source": [
    "## Defining the Variational Autoencoder network\n",
    "##### Based on the original code from the course exercise, but modified to be able to control number of layers, dimensions of layers and use the hurdle-normal distribution as observation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106cb8f0-b9b6-4af1-83fd-d711b476fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    \"\"\"A Variational Autoencoder with\n",
    "    * a Bernoulli observation model `p_\\theta(x | z) = B(x | g_\\theta(z))`\n",
    "    * a Gaussian prior `p(z) = N(z | 0, I)`\n",
    "    * a Gaussian posterior `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int, encoder_layer_sizes:list, decoder_layer_sizes:list) -> None:\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Defining parameters of model\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        \n",
    "        self.encoder_layer_sizes = encoder_layer_sizes\n",
    "        self.n_encoder_layers = len(encoder_layer_sizes)\n",
    "        \n",
    "        self.decoder_layer_sizes = decoder_layer_sizes\n",
    "        self.n_decoder_layers = len(decoder_layer_sizes)\n",
    "        \n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Defining flexible encoder\n",
    "        encoder_layers = [nn.Linear(self.observation_features, self.encoder_layer_sizes[0]), nn.BatchNorm1d(self.encoder_layer_sizes[0])] # input layer\n",
    "        encoder_layers.append(nn.LeakyReLU()) # Make it non-linear\n",
    "        for i in range(self.n_encoder_layers-1):\n",
    "            encoder_layers.append(nn.Linear(self.encoder_layer_sizes[i], self.encoder_layer_sizes[i+1]))\n",
    "            encoder_layers.append(nn.BatchNorm1d(self.encoder_layer_sizes[i+1]))\n",
    "            encoder_layers.append(nn.LeakyReLU())\n",
    "        encoder_layers.append(nn.Linear(self.encoder_layer_sizes[-1], self.latent_features*2)) # output layer\n",
    "        \n",
    "        # Inference Network\n",
    "        # Encode the observation `x` into the parameters of the posterior distribution\n",
    "        # `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x)), \\mu(x),\\log\\sigma(x) = h_\\phi(x)`\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Defining flexible decoder\n",
    "        decoder_layers = [nn.Linear(self.latent_features, self.decoder_layer_sizes[-1]), nn.BatchNorm1d(self.decoder_layer_sizes[-1])] # input layer\n",
    "        decoder_layers.append(nn.LeakyReLU())\n",
    "        for i in range(self.n_decoder_layers-1, 0, -1):\n",
    "            decoder_layers.append(nn.Linear(self.decoder_layer_sizes[i], self.decoder_layer_sizes[i-1]))\n",
    "            decoder_layers.append(nn.BatchNorm1d(self.decoder_layer_sizes[i-1]))\n",
    "            decoder_layers.append(nn.LeakyReLU())\n",
    "        decoder_layers.append(nn.Linear(self.decoder_layer_sizes[0], self.observation_features*3)) # output layer\n",
    "        \n",
    "        # Generative Model\n",
    "        # Decode the latent sample `z` into the parameters of the observation model\n",
    "        # `p_\\theta(x | z) = \\prod_i B(x_i | g_\\theta(x))`\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # define the parameters of the prior, chosen as p(z) = N(0, I)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features]))) # defines a model state variable, which is not learnable\n",
    "        \n",
    "    # ------------------------------------------------------------------------------\n",
    "    # Distributions\n",
    "    # ------------------------------------------------------------------------------\n",
    "    def posterior(self, x:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `q(z|x) = N(z | \\mu(x), \\sigma(x))`\"\"\"\n",
    "        h_x = self.encoder(x) # compute the parameters of the posterior\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1) # splits h_x (which contains both both mean and std values) into 2 chunks along dim=-1\n",
    "        \n",
    "        # return a distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def prior(self, batch_size:int=1)-> Distribution:\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:]) # The * unpacks the tuple that -shape returns so that we return each element in the tuple instead (opposite of zip operation)\n",
    "        mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "        \n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def observation_model(self, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "        px_params = self.decoder(z)\n",
    "        px_mu, log_px_sigma, px_logit = px_params.chunk(3, dim=-1)\n",
    "        \n",
    "        return HurdleNormal(px_mu, log_px_sigma, px_logit)\n",
    "        \n",
    "    # ------------------------------------------------------------------------------\n",
    "    def forward(self, x) -> Dict[str, Any]:\n",
    "        \"\"\"compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)\"\"\"\n",
    "        \n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.posterior(x)\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        \n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}\n",
    "    \n",
    "    \n",
    "    def sample_from_prior(self, batch_size:int=100):\n",
    "        \"\"\"sample z~p(z) and return p(x|z)\"\"\"\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=batch_size)\n",
    "        \n",
    "        # sample the prior \n",
    "        z = pz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'z': z}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99816522-858e-4e78-a981-f53d3935dd71",
   "metadata": {},
   "source": [
    "## Variational inference\n",
    "##### Code unchanged from course exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622f1ca4-f21b-4e1c-89fc-e8a6956b7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(x:Tensor) -> Tensor:\n",
    "    \"\"\"for each datapoint: sum over all dimensions\"\"\"\n",
    "    return x.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "class VariationalInference(nn.Module):\n",
    "    def __init__(self, beta:float=1.):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, model:nn.Module, x:Tensor) -> Tuple[Tensor, Dict]:\n",
    "        \n",
    "        # forward pass through the model\n",
    "        outputs = model(x)\n",
    "\n",
    "        # unpack outputs\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        # evaluate log probabilities\n",
    "        log_px = reduce(px.log_prob(x)) # Probability of seeing input data \"x\" under hurdle normal distribution \"px\"\n",
    "        log_pz = reduce(pz.log_prob(z)) # Prior distribution\n",
    "        log_qz = reduce(qz.log_prob(z)) # Posterior distribution\n",
    "\n",
    "        # compute the ELBO with and without the beta parameter: \n",
    "        # `L^\\beta = E_q [ log p(x|z) ] - \\beta * D_KL(q(z|x) | p(z))`\n",
    "        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`\n",
    "        kl = log_qz - log_pz\n",
    "\n",
    "        elbo = torch.mean(log_px) - kl\n",
    "        beta_elbo = torch.mean(log_px) - self.beta * kl\n",
    "\n",
    "        # loss\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # prepare the output\n",
    "        with torch.no_grad():\n",
    "            diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}\n",
    "            \n",
    "        return loss, diagnostics, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e12729-3d77-49c8-a0aa-3f2b51c1f2bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train and test as functions\n",
    "##### This is in order to be able to use Ray Tune to search for optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb5d826-e28a-4e2f-80b6-fa13417e5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore all future warnings\n",
    "simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "# Load train and test sets outside of training function as we want to compare hyperparameters between identical sets of train and test\n",
    "train_loader, test_loader = data_loaders(batch_size=16, \n",
    "                                         num_workers=4, \n",
    "                                         pin_memory=True)\n",
    "# Only used to get shape of data\n",
    "data_train = next(iter(train_loader))\n",
    "\n",
    "\n",
    "def train_and_test(config):\n",
    "    \n",
    "    \n",
    "    # Function checkpointing (Ray Tune)\n",
    "    step = 0\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        last_step = loaded_checkpoint.to_dict()[\"step\"]\n",
    "        step = last_step + 1\n",
    "    \n",
    "    # Initialize epochs\n",
    "    num_epochs = 100\n",
    "    epoch = 0\n",
    "\n",
    "    \n",
    "    # Initialize model\n",
    "    vae = VariationalAutoencoder(data_train[0].shape,\n",
    "                                 config['latent_features'], \n",
    "                                 config['encoder_layer_sizes'], \n",
    "                                 config['decoder_layer_sizes'])\n",
    "    \n",
    "    # Check if GPU is available, else use CPU\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Transfer model to device\n",
    "    vae = vae.to(device)\n",
    "    \n",
    "    # Evaluator: Variational Inference\n",
    "    beta = 1\n",
    "    vi = VariationalInference(beta=beta)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(vae.parameters(), \n",
    "                                 lr = config['lr'],\n",
    "                                 weight_decay = config['weight_decay'])\n",
    "    \n",
    "    # define dictionary to store the training curves\n",
    "    training_data = defaultdict(list)\n",
    "    validation_data = defaultdict(list)\n",
    "    \n",
    "    while epoch < num_epochs:\n",
    "        epoch+= 1\n",
    "        # print(f\"######## Epoch: {epoch} of {num_epochs} ########\")\n",
    "        training_epoch_data = defaultdict(list)\n",
    "        vae.train()\n",
    "\n",
    "        # Go through each batch in the training dataset using the loader\n",
    "        for x in train_loader:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            # perform a forward pass through the model and compute the ELBO\n",
    "            loss, diagnostics, outputs = vi(vae, x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # gather data for the current bach\n",
    "            for k, v in diagnostics.items():\n",
    "                training_epoch_data[k] += [v.mean().item()]\n",
    "\n",
    "\n",
    "        # gather data for the full epoch\n",
    "        for k, v in training_epoch_data.items():\n",
    "            training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "        # Evaluate on a single batch, do not propagate gradients\n",
    "        with torch.no_grad():\n",
    "            vae.eval()\n",
    "\n",
    "            # Just load a single batch from the test loader\n",
    "            x = next(iter(test_loader))\n",
    "            x = x.to(device)\n",
    "\n",
    "\n",
    "            # perform a forward pass through the model and compute the ELBO\n",
    "            loss, diagnostics, outputs = vi(vae, x)\n",
    "     \n",
    "            \n",
    "            # gather data for the validation step\n",
    "            for k, v in diagnostics.items():\n",
    "                validation_data[k] += [v.mean().item()]\n",
    "\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict({\"step\": step})\n",
    "        session.report({\"test_loss\": validation_data['elbo'][-1],\"train_loss\": training_data['elbo'][-1]}, checkpoint=checkpoint)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930bb22-92cf-42dd-a766-1414e8ea737a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Run the grid search using ASHA scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b375831b-0495-4b87-af0c-f627faa166c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 15:40:01,615\tWARNING function_trainable.py:586 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-21 15:40:52</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:50.71        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.3/50.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=5<br>Bracket: Iter 60.000: -1167.0548502604167 | Iter 20.000: -1433.572509765625<br>Resources requested: 0/16 CPUs, 0/1 GPUs, 0.0/25.66 GiB heap, 0.0/12.83 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc              </th><th>decoder_layer_sizes  </th><th>encoder_layer_sizes  </th><th style=\"text-align: right;\">  latent_features</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  test_loss</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_test_59b56_00000</td><td>TERMINATED</td><td>172.27.30.56:8003</td><td>[512, 512]           </td><td>[256, 256, 256]      </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        0.1   </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        16.2581 </td><td style=\"text-align: right;\">   -1236.73</td><td style=\"text-align: right;\">    -723.993</td></tr>\n",
       "<tr><td>train_and_test_59b56_00001</td><td>TERMINATED</td><td>172.27.30.56:8003</td><td>[512, 512]           </td><td>[256, 256, 256]      </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        16.2345 </td><td style=\"text-align: right;\">   -1303.64</td><td style=\"text-align: right;\">    -762.466</td></tr>\n",
       "<tr><td>train_and_test_59b56_00002</td><td>TERMINATED</td><td>172.27.30.56:8003</td><td>[512, 512]           </td><td>[256, 256, 256]      </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         9.90825</td><td style=\"text-align: right;\">   -1173.18</td><td style=\"text-align: right;\">    -869.578</td></tr>\n",
       "<tr><td>train_and_test_59b56_00003</td><td>TERMINATED</td><td>172.27.30.56:8003</td><td>[512, 512]           </td><td>[256, 256, 256]      </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         3.20855</td><td style=\"text-align: right;\">   -1498.96</td><td style=\"text-align: right;\">   -1401.67 </td></tr>\n",
       "<tr><td>train_and_test_59b56_00004</td><td>TERMINATED</td><td>172.27.30.56:8003</td><td>[512, 512]           </td><td>[256, 256, 256]      </td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         3.30282</td><td style=\"text-align: right;\">   -1519.25</td><td style=\"text-align: right;\">   -1414.84 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip     </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  test_loss</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_test_59b56_00000</td><td>2022-12-21_15-40-19</td><td>True  </td><td>                </td><td>626d860d6330494da4182290b5d9211b</td><td>DESKTOP-3I4L4RQ</td><td style=\"text-align: right;\">                       100</td><td>172.27.30.56</td><td style=\"text-align: right;\"> 8003</td><td>True               </td><td style=\"text-align: right;\">   -1236.73</td><td style=\"text-align: right;\">            16.2581 </td><td style=\"text-align: right;\">          0.15847 </td><td style=\"text-align: right;\">      16.2581 </td><td style=\"text-align: right;\"> 1671633619</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">    -723.993</td><td style=\"text-align: right;\">                 100</td><td>59b56_00000</td><td style=\"text-align: right;\">   0.00217795</td></tr>\n",
       "<tr><td>train_and_test_59b56_00001</td><td>2022-12-21_15-40-35</td><td>True  </td><td>                </td><td>626d860d6330494da4182290b5d9211b</td><td>DESKTOP-3I4L4RQ</td><td style=\"text-align: right;\">                       100</td><td>172.27.30.56</td><td style=\"text-align: right;\"> 8003</td><td>True               </td><td style=\"text-align: right;\">   -1303.64</td><td style=\"text-align: right;\">            16.2345 </td><td style=\"text-align: right;\">          0.149805</td><td style=\"text-align: right;\">      16.2345 </td><td style=\"text-align: right;\"> 1671633635</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">    -762.466</td><td style=\"text-align: right;\">                 100</td><td>59b56_00001</td><td style=\"text-align: right;\">   0.00217795</td></tr>\n",
       "<tr><td>train_and_test_59b56_00002</td><td>2022-12-21_15-40-45</td><td>True  </td><td>                </td><td>626d860d6330494da4182290b5d9211b</td><td>DESKTOP-3I4L4RQ</td><td style=\"text-align: right;\">                        60</td><td>172.27.30.56</td><td style=\"text-align: right;\"> 8003</td><td>True               </td><td style=\"text-align: right;\">   -1173.18</td><td style=\"text-align: right;\">             9.90825</td><td style=\"text-align: right;\">          0.15564 </td><td style=\"text-align: right;\">       9.90825</td><td style=\"text-align: right;\"> 1671633645</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">    -869.578</td><td style=\"text-align: right;\">                  60</td><td>59b56_00002</td><td style=\"text-align: right;\">   0.00217795</td></tr>\n",
       "<tr><td>train_and_test_59b56_00003</td><td>2022-12-21_15-40-49</td><td>True  </td><td>                </td><td>626d860d6330494da4182290b5d9211b</td><td>DESKTOP-3I4L4RQ</td><td style=\"text-align: right;\">                        20</td><td>172.27.30.56</td><td style=\"text-align: right;\"> 8003</td><td>True               </td><td style=\"text-align: right;\">   -1498.96</td><td style=\"text-align: right;\">             3.20855</td><td style=\"text-align: right;\">          0.15384 </td><td style=\"text-align: right;\">       3.20855</td><td style=\"text-align: right;\"> 1671633649</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">   -1401.67 </td><td style=\"text-align: right;\">                  20</td><td>59b56_00003</td><td style=\"text-align: right;\">   0.00217795</td></tr>\n",
       "<tr><td>train_and_test_59b56_00004</td><td>2022-12-21_15-40-52</td><td>True  </td><td>                </td><td>626d860d6330494da4182290b5d9211b</td><td>DESKTOP-3I4L4RQ</td><td style=\"text-align: right;\">                        20</td><td>172.27.30.56</td><td style=\"text-align: right;\"> 8003</td><td>True               </td><td style=\"text-align: right;\">   -1519.25</td><td style=\"text-align: right;\">             3.30282</td><td style=\"text-align: right;\">          0.153418</td><td style=\"text-align: right;\">       3.30282</td><td style=\"text-align: right;\"> 1671633652</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">   -1414.84 </td><td style=\"text-align: right;\">                  20</td><td>59b56_00004</td><td style=\"text-align: right;\">   0.00217795</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-21 15:40:52,469\tINFO tune.py:777 -- Total run time: 50.85 seconds (50.70 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='test_loss',\n",
    "    mode='max',\n",
    "    max_t=100,\n",
    "    grace_period=20,\n",
    "    reduction_factor=3,\n",
    "    brackets=1)\n",
    "\n",
    "trainable_with_gpu = tune.with_resources(train_and_test, {\"gpu\": 1})\n",
    "\n",
    "# Here we define the hyperparameter search space for our grid search - this is nowhere near exhaustive as we are resource limited.\n",
    "search_space = {    'latent_features': tune.grid_search([4]), \n",
    "                    'encoder_layer_sizes': tune.grid_search([[256,256,256]]), \n",
    "                    'decoder_layer_sizes': tune.grid_search([[512,512]]), \n",
    "                    'lr': tune.grid_search([1e-3]),\n",
    "                    'weight_decay': tune.grid_search([1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
    "               }\n",
    "\n",
    "tuner = tune.Tuner(trainable_with_gpu, \n",
    "                   tune_config=tune.TuneConfig(scheduler=asha_scheduler),\n",
    "                   #metric=\"test_loss\", mode=\"max\", \n",
    "                   run_config=air.RunConfig(name = \"subset-21-12-2022\", local_dir=\"./ray_results\"),\n",
    "                   # https://docs.ray.io/en/latest/ray-air/package-ref.html#module-ray.tune.tune_config\n",
    "                   param_space = search_space)\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f02696-0c54-40af-b67c-31e464634f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config is: {'latent_features': 4, 'encoder_layer_sizes': [256, 256, 256], 'decoder_layer_sizes': [512, 512], 'lr': 0.001, 'weight_decay': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best config is:\", results.get_best_result(metric=\"test_loss\", mode=\"max\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f045325e-12e7-4f1c-bcb2-97c258ddaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVE RESULTS DATAFRAME TO DISK\n",
    "tune_df = results.get_dataframe()\n",
    "tune_df.to_pickle(os.getcwd() + \"/ray_results/20_subset-04-12-2022.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cda3c085-94e3-47df-8611-64ae16e6e964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>...</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>warmup_time</th>\n",
       "      <th>config/decoder_layer_sizes</th>\n",
       "      <th>config/encoder_layer_sizes</th>\n",
       "      <th>config/latent_features</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>config/weight_decay</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1173.184570</td>\n",
       "      <td>-869.578064</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>59b56_00002</td>\n",
       "      <td>626d860d6330494da4182290b5d9211b</td>\n",
       "      <td>...</td>\n",
       "      <td>9.908249</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[256, 256, 256]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>/mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1236.729248</td>\n",
       "      <td>-723.992590</td>\n",
       "      <td>0.158470</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>59b56_00000</td>\n",
       "      <td>626d860d6330494da4182290b5d9211b</td>\n",
       "      <td>...</td>\n",
       "      <td>16.258105</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[256, 256, 256]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>/mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1303.643066</td>\n",
       "      <td>-762.465857</td>\n",
       "      <td>0.149805</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>59b56_00001</td>\n",
       "      <td>626d860d6330494da4182290b5d9211b</td>\n",
       "      <td>...</td>\n",
       "      <td>16.234467</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[256, 256, 256]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>/mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1498.958862</td>\n",
       "      <td>-1401.672168</td>\n",
       "      <td>0.153840</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>59b56_00003</td>\n",
       "      <td>626d860d6330494da4182290b5d9211b</td>\n",
       "      <td>...</td>\n",
       "      <td>3.208551</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[256, 256, 256]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>/mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1519.248779</td>\n",
       "      <td>-1414.836255</td>\n",
       "      <td>0.153418</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>59b56_00004</td>\n",
       "      <td>626d860d6330494da4182290b5d9211b</td>\n",
       "      <td>...</td>\n",
       "      <td>3.302817</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[256, 256, 256]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>/mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_loss   train_loss  time_this_iter_s  should_checkpoint  done  \\\n",
       "2 -1173.184570  -869.578064          0.155640               True  True   \n",
       "0 -1236.729248  -723.992590          0.158470               True  True   \n",
       "1 -1303.643066  -762.465857          0.149805               True  True   \n",
       "3 -1498.958862 -1401.672168          0.153840               True  True   \n",
       "4 -1519.248779 -1414.836255          0.153418               True  True   \n",
       "\n",
       "   timesteps_total  episodes_total  training_iteration     trial_id  \\\n",
       "2              NaN             NaN                  60  59b56_00002   \n",
       "0              NaN             NaN                 100  59b56_00000   \n",
       "1              NaN             NaN                 100  59b56_00001   \n",
       "3              NaN             NaN                  20  59b56_00003   \n",
       "4              NaN             NaN                  20  59b56_00004   \n",
       "\n",
       "                      experiment_id  ... time_since_restore  \\\n",
       "2  626d860d6330494da4182290b5d9211b  ...           9.908249   \n",
       "0  626d860d6330494da4182290b5d9211b  ...          16.258105   \n",
       "1  626d860d6330494da4182290b5d9211b  ...          16.234467   \n",
       "3  626d860d6330494da4182290b5d9211b  ...           3.208551   \n",
       "4  626d860d6330494da4182290b5d9211b  ...           3.302817   \n",
       "\n",
       "   timesteps_since_restore  iterations_since_restore  warmup_time  \\\n",
       "2                        0                        60     0.002178   \n",
       "0                        0                       100     0.002178   \n",
       "1                        0                       100     0.002178   \n",
       "3                        0                        20     0.002178   \n",
       "4                        0                        20     0.002178   \n",
       "\n",
       "  config/decoder_layer_sizes config/encoder_layer_sizes  \\\n",
       "2                 [512, 512]            [256, 256, 256]   \n",
       "0                 [512, 512]            [256, 256, 256]   \n",
       "1                 [512, 512]            [256, 256, 256]   \n",
       "3                 [512, 512]            [256, 256, 256]   \n",
       "4                 [512, 512]            [256, 256, 256]   \n",
       "\n",
       "   config/latent_features  config/lr  config/weight_decay  \\\n",
       "2                       4      0.001              0.00100   \n",
       "0                       4      0.001              0.10000   \n",
       "1                       4      0.001              0.01000   \n",
       "3                       4      0.001              0.00010   \n",
       "4                       4      0.001              0.00001   \n",
       "\n",
       "                                              logdir  \n",
       "2  /mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...  \n",
       "0  /mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...  \n",
       "1  /mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...  \n",
       "3  /mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...  \n",
       "4  /mnt/c/Users/caspe/Desktop/UnixWorkplace/Deep ...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the full dataframe of tested hyperparameter combinations sorted by lowest test loss\n",
    "tune_df.sort_values(by = ['test_loss'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744dc09-a811-4628-ac3e-1c04e8fd5398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL_Project]",
   "language": "python",
   "name": "conda-env-DL_Project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
